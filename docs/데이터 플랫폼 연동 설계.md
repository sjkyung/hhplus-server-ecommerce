# Kafka 기반 데이터 플랫폼 연동 구조 설계 문서

## 개요

기존에는 서비스 내에서 HTTP 또는 직접 의존 방식으로 데이터 플랫폼에 정보를 전달하던 구조를 사용했으나, 이벤트 드리븐 아키텍처 적용을 통해 Kafka 기반 전송 방식으로 변경하였습니다.

---

## 기존 방식 (AS-IS)

- 서비스에서 검증 및 저장 후 직접 데이터 플랫폼 서비스 호출 (예: RestTemplate, WebClient 등)
- 동기 방식으로 응답 대기 → 장애 전파 및 coupling 우려

```
Service -> DataPlatformService.send(data)
```

### 단점
- 데이터 플랫폼 서비스 장애 시 연쇄 장애 발생 가능
- 서비스 간 강한 결합도 존재
- 확장 및 유지보수 어려움

---

## 변경 방식 (TO-BE: Kafka 기반)

- 서비스에서 이벤트 발행 (`OrderDataPlatformSyncEvent`)
- `@TransactionalEventListener`로 Kafka 메시지 전송
- Kafka Listener가 데이터 플랫폼 전송 책임

### 구조

```
[서비스]
 └── publish(OrderDataPlatformSyncEvent)
        ↓
@KafkaListener → DataPlatformService.send(command)
```

---

## 예시 코드

### 1. 이벤트 발행

```kotlin
eventPublisher.publishEvent(OrderDataPlatformSyncEvent(order.id, order.userId, order.totalPrice))
```

### 2. 트랜잭션 커밋 이후 이벤트 핸들링

```kotlin
@TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT)
fun publishOrderEvent(event: OrderDataPlatformSyncEvent) {
    kafkaTemplate.send("order-topic", event)
}
```

### 3. Kafka Listener에서 데이터 플랫폼 전송

```kotlin
@KafkaListener(topics = ["order-topic"])
fun consumeOrder(event: OrderDataPlatformSyncEvent) {
    val dataPlatformCommand = DataPlatformCommand(
        orderId = event.orderId,
        userId = event.userId,
        totalPrice = event.totalPrice,
        sendTime = LocalDateTime.now()
    )
    dataPlatformService.send(dataPlatformCommand)
}
```

---

## 장점

- 서비스 간 의존도 제거 (완전 비동기화)
- 장애 전파 차단 → 이벤트 저장 후 처리 지연 허용 가능
- 재처리 가능성 확보 (Kafka의 durability 기반)

---

## 추후 개선점

- Fail-safe 및 Dead Letter Queue (DLQ) 구성
- 모니터링 및 리트라이 정책 고도화

---

## 테스트 전략

- `@SpyBean`으로 KafkaListener 호출 여부 검증
- Integration Test에서 실제 KafkaConsumer를 활용하여 메시지 수신 확인


